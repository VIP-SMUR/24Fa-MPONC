{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:22:28.111198Z",
     "start_time": "2024-10-07T02:22:28.104546Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "\n",
    "EPSILON = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:41:12.299570Z",
     "start_time": "2024-10-07T02:41:12.279140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    def plot(self, cmap='YlOrRd', figkey=None):\\n\\n        for u, data in self.g.nodes(data=True):\\n            if not data['amt']: # Non-transit nodes\\n                data['dow'] = np.average(self.agt_dows, weights=[a.avg_probabilities[u] for a in self.agts]) # Average endowment\\n                data['dow'] = (data['dow'] - min(city.agt_dows)) / (max(city.agt_dows) - min(city.agt_dows)) # Normalize\\n                \\n                data['pop'] = np.sum([a.avg_probabilities[u] for a in self.agts]) # Sum agent probabilities to be at the node\\n            else: # Transit nodes\\n                data['dow'] = np.nan\\n                data['pop'] = np.nan\\n\\n        # ===============================\\n        # SIMULATION VISUALIZATION - CODE\\n        # ===============================\\n        no_agts = len(self.agts) # Number of agents\\n        \\n        \\n        # Size of nodes\\n        node_size = [no_agts / 10 * data['pop'] if not data['amt'] else no_agts / 2.5 for _, data in self.g.nodes(data=True)]\\n        \\n        # Color of nodes\\n        node_color = ox.plot.get_node_colors_by_attr(self.g, 'dow', start=0, stop=1, na_color='b', cmap=cmap)\\n        \\n        fig, ax = plt.subplots(figsize=(9, 6))\\n\\n        # COLORBAR\\n        cb = fig.colorbar(\\n            plt.cm.ScalarMappable(cmap=plt.colormaps[cmap]), ax=ax, location='bottom', shrink=0.5, pad=0.05\\n        )\\n        cb.set_label('Expected Endowment', fontsize=14)\\n        \\n        # PLOT GRAPH\\n        ox.plot_graph(self.g, ax=ax, bgcolor='w', node_color=node_color, node_size=node_size)\\n        plt.show()\\n        \\n        if figkey is not None:\\n            plt.savefig('./figures/{0}.pdf'.format(figkey), bbox_inches='tight', format='pdf')\\n        # Save graph as pdf in './figures/' directory if 'figkey' is provided\\n        \""
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class City:\n",
    "\n",
    "    # CONSTRUCTOR\n",
    "    def __init__(self, housing, amts, rho=2): #default rho (house capacity) == 2\n",
    "\n",
    "        self.rho = rho #house capacity\n",
    "        self.amts = amts #amenity list\n",
    "        self.housing = housing #housing list\n",
    "        \n",
    "        # Create dictionary containing ID and tuple from 'housing' list\n",
    "        self.housingDict = {} \n",
    "        for ID, (lat, lon, name, beltline) in enumerate(self.housing): #Iterate through each housing node\n",
    "            self.housingDict[ID] = {\n",
    "                'lat': lat, # Latitude\n",
    "                'lon': lon, # Longitude\n",
    "                'name': name, # Housing name (region)\n",
    "                'beltline': beltline,  # Is it in the Beltline?\n",
    "                \n",
    "                'amt': False,  # Is it an amenity?\n",
    "                'inh': set(),  # Set containing all Agent inhabitants\n",
    "                'dow_thr': 0.0,  # Endowment threshold initialized to 0\n",
    "                'upk': False,  # Upkeep score\n",
    "                'cmt': 0.0,  # Community score\n",
    "                'pop_hist': [], # Population history\n",
    "                'cmt_hist': []  # Community history\n",
    "            }\n",
    "            \n",
    "        #Create dictionary containing ID and tuple from 'amts' list\n",
    "        self.amtsDict = {}\n",
    "        for ID, (lat, lon, name, beltline) in enumerate(self.amts): #Iterate through each housing node\n",
    "            self.amtsDict[ID+len(self.housing)] = {\n",
    "                'lat': lat, # Latitude\n",
    "                'lon': lon, # Longitude\n",
    "                'name': name, # Name\n",
    "                'beltline': beltline,  # Is it in the Beltline?\n",
    "                \n",
    "                'amt': True,  # Is it an amenity?\n",
    "\n",
    "                'inh': None,  # Set containing all Agent inhabitants\n",
    "                'dow_thr': None, # Endowment threshold initialized to 0\n",
    "                'upk': None,  # Upkeep score\n",
    "                'cmt': 0.0,  # Community score\n",
    "                'pop_hist': None,  # Population history\n",
    "                'cmt_hist': None  # Community history\n",
    "            }\n",
    "\n",
    "        # Set transit amenities [GRAPH APPROACH]\n",
    "        '''def set_amts(self, amts):\n",
    "        self.amts = amts\n",
    "        for u in self.amts:\n",
    "            data = self.housingDict[u]\n",
    "            \n",
    "            # Node characteristics of an amenity node\n",
    "            data['amt'] = True\n",
    "            data['beltline'] = self.amts[u][3]\n",
    "            data['inh'] = None\n",
    "            data['dow_thr'] = None\n",
    "            data['upk'] = None\n",
    "            data['cmt'] = None\n",
    "            data['pop_hist'] = None\n",
    "            data['cmt_hist'] = None\n",
    "            \n",
    "        # Calculate shortest distance between each housing node & transit node \n",
    "        # NECESSARY FOR ACCESSIBILITY SCORE\n",
    "        if len(self.amts) == 0:\n",
    "            self.amts_dist = None\n",
    "        else:\n",
    "            self.amts_dist = np.array([self.calcDistance(node1, node2) for node1 in self.housing for node2 in self.amts])'''\n",
    "        \n",
    "        # Dictionary containing all nodes\n",
    "        self.allNodes = {**self.housingDict, **self.amtsDict}\n",
    "\n",
    "        # Fill self.housing_dist [GRAPH APPROACH] \n",
    "        ''' \n",
    "        self.diam = nx.diameter(self.g, weight='length') #Longest shortest path between any two nodes on graph\n",
    "        \n",
    "        #Normalized shortest paths between all pairs of nodes\n",
    "        self.housing_dist = dict(nx.all_pairs_dijkstra_path_length(self.g, weight='length'))\n",
    "        self.housing_dist = pd.DataFrame.from_dict(self.housing_dist).sort_index() / self.diam #\n",
    "        self.housing_dist = self.housing_dist.to_numpy()'''\n",
    "\n",
    "        self.housing_dist = {} # Dictionary of distances btw housing node pairs   \n",
    "        if len(self.housingDict) != 0:\n",
    "            self.get_housing_distances() # Fill self.housing_dist dictionary\n",
    "\n",
    "        self.amts_dist = {} # Dictionary of distances btw housing and amenity \n",
    "        if len(self.amtsDict) != 0:\n",
    "            self.get_amt_distances() # Fill self.housing_dist dictionary\n",
    "\n",
    "        self.agts = None #List of agents\n",
    "        self.agt_dows = None #List of agent endowments\n",
    "\n",
    "\n",
    "    # HELPER FUNCTION - fill self.housing_dist dictionary\n",
    "    def get_housing_distances(self):\n",
    "        numHousing = len(self.housingDict)\n",
    "        self.housing_dist = np.zeros((numHousing, numHousing))\n",
    "        \n",
    "        for ID1, node1 in self.housingDict.items():\n",
    "            for ID2, node2 in self.housingDict.items():\n",
    "                if ID1 <= ID2:  \n",
    "                    # Indices [ID1][ID2] & [ID2][ID1] have the same distance\n",
    "                    distance = self.calcDistance(node1, node2)\n",
    "                    self.housing_dist[ID1][ID2] = distance\n",
    "                    self.housing_dist[ID2][ID1] = distance\n",
    "\n",
    "        #normalize with longest shortest distance\n",
    "        if np.max(self.housing_dist) != 0:\n",
    "            self.housing_dist = self.housing_dist / np.max(self.housing_dist)\n",
    "        else:\n",
    "            self.housing_dist = np.zeros_like(self.housing_dist)\n",
    "    \n",
    "    # HELPER FUNCTION - fill self.amts_dist dictionary\n",
    "    def get_amt_distances(self):\n",
    "        numHousing = len(self.housingDict)\n",
    "        numAmts = len(self.amtsDict)\n",
    "        self.amts_dist = np.zeros((numHousing, numAmts))\n",
    "        \n",
    "        for ID1, node1 in self.housingDict.items():\n",
    "            for ID2, node2 in self.amtsDict.items():\n",
    "                distance = self.calcDistance(node1, node2)\n",
    "                self.amts_dist[ID1][ID2 - len(self.housing)] = distance\n",
    "\n",
    "        #normalize with longest shortest distance\n",
    "        if self.amts_dist.size != 0:\n",
    "            self.amts_dist = self.amts_dist / np.max(self.amts_dist) \n",
    "\n",
    "    # HELPER FUNCTION - calculates distance between ANY two nodes\n",
    "    def calcDistance(self, node1, node2):\n",
    "        # PROCESS FOR CALCULATING (HAVERSINE) GEOGRAPHIC DISTANCES\n",
    "        R = 6371.0 # Earth radius (km)\n",
    "        lat1 = np.radians(node1['lat'])\n",
    "        lon1 = np.radians(node1['lon'])\n",
    "        lat2 = np.radians(node2['lat'])\n",
    "        lon2 = np.radians(node2['lon'])\n",
    "\n",
    "        # Haversine formula\n",
    "        a = np.sin((lat2 - lat1) / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin((lon2 - lon1) / 2)**2\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "        distance = R * c\n",
    "        return distance\n",
    "\n",
    "    def set_agts(self, agts):\n",
    "        self.agts = agts #list of agents\n",
    "        self.agt_dows = np.array([a.dow for a in self.agts]) #array of agent endowments\n",
    "\n",
    "    # Update each node\n",
    "    def update(self):   \n",
    "        for ID, data in self.housingDict.items(): # Iterate through dict\n",
    "            # Skip amenity nodes\n",
    "            if data['amt']:\n",
    "                continue\n",
    "\n",
    "            pop = len(data['inh']) # Population\n",
    "            inhabitant_dows = [a.dow for a in data['inh']]  # Array of endowments of node's inhabitants\n",
    "            \n",
    "            # COMMUNITY SCORE (average endowment)\n",
    "            cmt = 0.0 #TODO: review logic: set to 0 if population is 0?\n",
    "            if pop > 0:\n",
    "                #average endowment of agents in set data['inh'], weighted by alpha\n",
    "                cmt = np.average(inhabitant_dows, weights=[(1 - self.housing_dist[ID][a.u]) ** 2 for a in data['inh']]) # Community value of node\n",
    "                \n",
    "                data['cmt'] = cmt\n",
    "            \n",
    "            # UPKEEP SCORE\n",
    "            # ENDOWMENT THRESHOLD\n",
    "            if pop > 0: # If inhabited\n",
    "                if pop < self.rho:\n",
    "                    data['dow_thr'] = 0.0\n",
    "                else:\n",
    "                    data['dow_thr'] = sorted([a.dow for a in data['inh']])[-self.rho] # Lowest endowment value if Population = Rho\n",
    "                data['upk'] = True\n",
    "                \n",
    "            else: # If uninhabited\n",
    "                data['dow_thr'] = 0.0\n",
    "                data['upk'] = False\n",
    "\n",
    "            # Update population history\n",
    "            data['pop_hist'].append(pop)\n",
    "            \n",
    "            # Update Community history (average endowment)\n",
    "            data['cmt_hist'].append(cmt)\n",
    "        \n",
    "\n",
    "#[GRAPH APPROACH]\n",
    "# 'plot' function\n",
    "'''\n",
    "    def plot(self, cmap='YlOrRd', figkey=None):\n",
    "\n",
    "        for u, data in self.g.nodes(data=True):\n",
    "            if not data['amt']: # Non-transit nodes\n",
    "                data['dow'] = np.average(self.agt_dows, weights=[a.avg_probabilities[u] for a in self.agts]) # Average endowment\n",
    "                data['dow'] = (data['dow'] - min(city.agt_dows)) / (max(city.agt_dows) - min(city.agt_dows)) # Normalize\n",
    "                \n",
    "                data['pop'] = np.sum([a.avg_probabilities[u] for a in self.agts]) # Sum agent probabilities to be at the node\n",
    "            else: # Transit nodes\n",
    "                data['dow'] = np.nan\n",
    "                data['pop'] = np.nan\n",
    "\n",
    "        # ===============================\n",
    "        # SIMULATION VISUALIZATION - CODE\n",
    "        # ===============================\n",
    "        no_agts = len(self.agts) # Number of agents\n",
    "        \n",
    "        \n",
    "        # Size of nodes\n",
    "        node_size = [no_agts / 10 * data['pop'] if not data['amt'] else no_agts / 2.5 for _, data in self.g.nodes(data=True)]\n",
    "        \n",
    "        # Color of nodes\n",
    "        node_color = ox.plot.get_node_colors_by_attr(self.g, 'dow', start=0, stop=1, na_color='b', cmap=cmap)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "        # COLORBAR\n",
    "        cb = fig.colorbar(\n",
    "            plt.cm.ScalarMappable(cmap=plt.colormaps[cmap]), ax=ax, location='bottom', shrink=0.5, pad=0.05\n",
    "        )\n",
    "        cb.set_label('Expected Endowment', fontsize=14)\n",
    "        \n",
    "        # PLOT GRAPH\n",
    "        ox.plot_graph(self.g, ax=ax, bgcolor='w', node_color=node_color, node_size=node_size)\n",
    "        plt.show()\n",
    "        \n",
    "        if figkey is not None:\n",
    "            plt.savefig('./figures/{0}.pdf'.format(figkey), bbox_inches='tight', format='pdf')\n",
    "        # Save graph as pdf in './figures/' directory if 'figkey' is provided\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:30:25.078038Z",
     "start_time": "2024-10-07T02:30:25.071756Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, i, dow, city, alpha=0.5):\n",
    "\n",
    "        self.i = i # Agent instance identifier\n",
    "        self.dow = dow #endowment\n",
    "        self.city = city #city\n",
    "        self.alpha = alpha #Transit_access/Community weight\n",
    "\n",
    "        self.weights = [1] * len(self.city.housingDict)\n",
    "        self.probabilities = [1] * len(self.city.housingDict) # Each element corresponds to a different node\n",
    "        self.tot_probabilities = 0.0 # Total probabilities of going to each node, added up\n",
    "        self.avg_probabilities = None # Used for graphing purposes\n",
    "        self.u = None\n",
    "\n",
    "        self.reset()\n",
    "        \n",
    "    # Create hash identifier\n",
    "    def __hash__(self):\n",
    "        return hash(self.i)\n",
    "\n",
    "    def __eq__(self, other): \n",
    "        return self.i == other.i\n",
    "\n",
    "# RESET METHOD\n",
    "# Starting point at beginning of simulation\n",
    "    def reset(self):\n",
    "        # Normalize probabilities\n",
    "        self.probabilities[:] = [a/len(self.probabilities) for a in self.probabilities]\n",
    "        \n",
    "        self.tot_probabilities = np.sum(self.probabilities)\n",
    "        \n",
    "        # Current node - Initialize starting position at random node (based on weights)\n",
    "        self.u = np.random.choice(list(self.city.housingDict.keys()), p=self.probabilities) \n",
    "        \n",
    "        # Adds self to node\n",
    "        self.city.housingDict[self.u]['inh'].add(self)\n",
    "\n",
    "# ACTION METHOD\n",
    "    def act(self): \n",
    "        # Leave node\n",
    "        self.city.housingDict[self.u]['inh'].remove(self) \n",
    "    \n",
    "        # Choose another node\n",
    "        self.u = np.random.choice(list(self.city.housingDict.keys()), p=self.probabilities) \n",
    "    \n",
    "        # Join node\n",
    "        self.city.housingDict[self.u]['inh'].add(self) \n",
    "        \n",
    "# LEARN METHOD\n",
    "    def learn(self):\n",
    "        for ID, _ in self.city.housingDict.items(): # for each node\n",
    "            self.weights[ID] *= (1 - EPSILON * self.cost(ID)) # adjust probability weights based off Cost Function\n",
    "        \n",
    "        self.probabilities = np.array(self.weights / np.sum(self.weights)) # (normalize) self.probabilities; each element is the probability of going to that node\n",
    "        \n",
    "        #TODO: Set self.tot_probabilities to 0 before adding up new self.probabilities?\n",
    "        for a in self.probabilities:\n",
    "            self.tot_probabilities += a # used for averaging purposes\n",
    "\n",
    "# COST FUNCTION\n",
    "    def cost(self, ID):\n",
    "        \n",
    "        # AFFORDABILITY SCORE\n",
    "        # 1 if self.dow >= node.dow_thr; else 0\n",
    "        aff = int(self.dow >= self.city.housingDict[ID]['dow_thr'])\n",
    "        \n",
    "        # UPKEEP SCORE\n",
    "        # 1 if upkeep == True; else 0\n",
    "        upk = int(self.city.housingDict[ID]['upk'])\n",
    "        \n",
    "        # BELTLINE SCORE\n",
    "        # 1 if in beltline; else 0\n",
    "        beltline = int(self.city.housingDict[ID]['beltline'])\n",
    "    \n",
    "        # DISTANCE SCORE\n",
    "        # 1 if no amenities, \n",
    "        if  not self.city.amtsDict: \n",
    "            loc = 1 \n",
    "        else:\n",
    "            loc = np.exp(- (1 - self.alpha) * self.city.amts_dist[ID])\n",
    "        \n",
    "        # COMMUNITY SCORE\n",
    "        # Difference between node 'cmt' value and self.dow.\n",
    "        cmt = np.exp(- self.alpha * np.abs(self.dow - self.city.housingDict[ID]['cmt']))\n",
    "    \n",
    "        # COST FUNCTION\n",
    "        c = 1 - aff * loc * beltline * upk * cmt\n",
    "        \n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:25:00.915559Z",
     "start_time": "2024-10-07T02:24:58.633375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tl_2022_us_zcta520.zip already exists in c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\\data. Skipping download.\n",
      "Extracting tl_2022_us_zcta520.zip to c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\\data\\tl_2022_us_zcta520...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 7/7 [00:04<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted tl_2022_us_zcta520.zip to c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\\data\\tl_2022_us_zcta520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_extract_file(url, filename):\n",
    "    # Use a 'data' subfolder in the current working directory\n",
    "    cwd = Path.cwd()\n",
    "    data_dir = cwd / \"data\"\n",
    "    data_dir.mkdir(exist_ok=True)  # Create the 'data' directory if it doesn't exist\n",
    "    file_path = data_dir / filename\n",
    "\n",
    "    # Create extraction subfolder name (remove .zip extension)\n",
    "    extract_folder_name = filename.rsplit('.', 1)[0]\n",
    "    extract_path = data_dir / extract_folder_name\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if file_path.exists():\n",
    "        print(f\"{filename} already exists in {data_dir}. Skipping download.\")\n",
    "    else:\n",
    "        # Make the request\n",
    "        print(f\"Downloading {filename} to {data_dir}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Get the total file size\n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "            # Open the file and use tqdm for the progress bar\n",
    "            with file_path.open('wb') as file, tqdm(\n",
    "                desc=filename,\n",
    "                total=total_size,\n",
    "                unit='iB',\n",
    "                unit_scale=True,\n",
    "                unit_divisor=1024,\n",
    "            ) as progress_bar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    size = file.write(data)\n",
    "                    progress_bar.update(size)\n",
    "            print(f\"Successfully downloaded {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n",
    "            return\n",
    "\n",
    "    # Extract the ZIP file\n",
    "    print(f\"Extracting {filename} to {extract_path}...\")\n",
    "    extract_path.mkdir(exist_ok=True)  # Create the extraction folder if it doesn't exist\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        # Get the total number of files in the ZIP\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        \n",
    "        # Use tqdm for the extraction progress bar\n",
    "        for file in tqdm(zip_ref.infolist(), desc=\"Extracting\", total=total_files):\n",
    "            zip_ref.extract(file, extract_path)\n",
    "    \n",
    "    print(f\"Successfully extracted {filename} to {extract_path}\")\n",
    "\n",
    "# URL of the file to download\n",
    "url = \"https://www2.census.gov/geo/tiger/TIGER2022/ZCTA520/tl_2022_us_zcta520.zip\"\n",
    "\n",
    "# Filename to save as\n",
    "filename = \"tl_2022_us_zcta520.zip\"\n",
    "\n",
    "# Call the function to download and extract the file\n",
    "download_and_extract_file(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:41:15.634203Z",
     "start_time": "2024-10-07T02:41:15.588402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\n",
      "t: 0\n",
      "t: 1\n",
      "t: 2\n",
      "t: 3\n",
      "t: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nif plot_cities:\\n    for rho in rho_l:\\n        for alpha in alpha_l:\\n            for t_max in t_max_l:\\n                with open(Path(cwd / 'data/{0}_{1}_{2}_{3}.pkl'.format(cty_key, rho, alpha, t_max)), 'rb') as file:\\n                    city = pickle.load(file)\\n                cmap = 'YlOrRd'\\n                figkey = '{0}_{1}_{2}_{3}'.format(cty_key, rho, alpha, t_max)\\n                city.plot(cmap=cmap, figkey=figkey)\\n                \""
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "print(cwd)\n",
    "figures_folder = Path(cwd / \"figures\")\n",
    "if not os.path.isdir(figures_folder):\n",
    "    os.makedirs(figures_folder)\n",
    "\n",
    "\n",
    "# Housing amenities [manual]\n",
    "# Use dummy coordinates for now\n",
    "housing = [\n",
    "    (0.0, 0.0, 'RDA/Cascade', True),\n",
    "    (0.0, 0.0, 'Pittsburgh/Peoplestown', True),\n",
    "    (0.0, 0.0, 'Boulevard Crossing', True),\n",
    "    (0.0, 0.0, 'Memorial Drive/Glenwood', True),\n",
    "    (0.0, 0.0, 'Freedom Parkway', True),\n",
    "    (0.0, 0.0, 'Virginia Highlands/Ansley', True),\n",
    "    (0.0, 0.0, 'Peachtree/Collier', True),\n",
    "    (0.0, 0.0, 'Upper Westside/Northside', True),\n",
    "    (0.0, 0.0, 'Simpson/Hollowell', True),\n",
    "    (0.0, 0.0, 'Upper Marietta/Westside Park', True),\n",
    "\n",
    "    (0.0, 0.0, 'Westlake HS', False), #4280\n",
    "    (0.0, 0.0, 'Wheeler HS', False), #4292\n",
    "    (0.0, 0.0, 'Lakeside HS', False), #4294\n",
    "    (0.0, 0.0, 'Druid Hills HS', False), #4307\n",
    "    (0.0, 0.0, 'McNair, Ronald E. HS', False), #4315\n",
    "    (0.0, 0.0, 'Brookhaven City', False), #4387\n",
    "    (0.0, 0.0, 'Decatur City', False), #4444\n",
    "    (0.0, 0.0, 'East Point City', False), #4459\n",
    "    (0.0, 0.0, 'Hapeville City', False), #4504\n",
    "    (0.0, 0.0, 'Sandy Springs City', False), #4646\n",
    "\n",
    "]\n",
    "\n",
    "# (GRAPH APPROACH - automate creation of nodes)\n",
    "'''\n",
    "load_g = False\n",
    "if not load_g:\n",
    "    gdf = gpd.read_file(cwd / Path('data/tl_2022_us_zcta520/tl_2022_us_zcta520.shp'))\n",
    "    gdf = gdf[gdf['ZCTA5CE20'] == '11206']\n",
    "    shape = gdf.iloc[0].geometry\n",
    "    g = ox.graph_from_polygon(shape, network_type='drive', simplify=True)\n",
    "    g = g.subgraph(max(nx.strongly_connected_components(g), key=len)).copy()\n",
    "    g = nx.convert_node_labels_to_integers(g)\n",
    "    with open(Path(cwd / 'data/tl_2022_us_zcta520/williamsburg.pkl'), 'wb') as file:\n",
    "        pickle.dump(g, file)\n",
    "else:\n",
    "    with open(Path(cwd / 'data/tl_2022_us_zcta520/williamsburg.pkl'), 'rb') as file:\n",
    "        g = pickle.load(file)\n",
    "amts = [ox.nearest_nodes(g, lon, lat) for lat, lon, _ in stations]\n",
    "'''\n",
    "\n",
    "# For now, don't consider transit amenities:\n",
    "# Tuple format: (lat) float, (lon) float, (name) string, (in beltline?) boolean\n",
    "amts = []\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# SIMULATION PRE-DETERMINED PARAMETERS\n",
    "# ====================================\n",
    "rho_l = [1] #1, 2, 4, 8 (for each iteration) rho-house capacity\n",
    "alpha_l = [0.25] #0.25, 0.75 (for each iteration) lambda-transit access vs. community value\n",
    "t_max_l = [5] #5000, 10000, 15000, 20000 (for each iteration) timesteps\n",
    "tau = 0.5 # inequality factor in Lorentz curve\n",
    "\n",
    "# RUN SIMULATION?\n",
    "run_experiments = True\n",
    "\n",
    "# PLOT SIMULATION?\n",
    "plot_cities = True\n",
    "\n",
    "cty_key = 'Atlanta'\n",
    "\n",
    "\n",
    "# ===============\n",
    "# SIMULATION CODE\n",
    "# ===============\n",
    "\n",
    "if run_experiments:\n",
    "    for rho in rho_l:\n",
    "        for alpha in alpha_l:\n",
    "\n",
    "            np.random.seed(0)\n",
    "\n",
    "            city = City(housing, amts, rho=rho)\n",
    "            #city.set_amts(amts) [graph approach to setting amenities]\n",
    "            n = len(city.allNodes)\n",
    "            \n",
    "            agt_dows = np.diff([1 - (1 - x) ** tau for x in np.linspace(0, 1, n + 1)])\n",
    "            agts = [Agent(i, dow, city, alpha=alpha) for i, dow in enumerate(agt_dows)]\n",
    "\n",
    "            city.set_agts(agts)\n",
    "            city.update()\n",
    "\n",
    "            for t in range(max(t_max_l)):\n",
    "                print('t: {0}'.format(t))\n",
    "                for a in agts:\n",
    "                    a.act()\n",
    "                city.update()\n",
    "                for a in agts:\n",
    "                    a.learn()\n",
    "\n",
    "                if t + 1 in t_max_l:\n",
    "\n",
    "                    for a in city.agts:\n",
    "                        a.avg_probabilities = a.tot_probabilities / (t + 1)\n",
    "\n",
    "                    with open(Path(cwd / 'data/{0}_{1}_{2}_{3}.pkl'.format(cty_key, rho, alpha, t + 1)), 'wb') as file:\n",
    "                        pickle.dump(city, file)\n",
    "\n",
    "#[GRAPH APPROACH]\n",
    "#TODO: figure out how to visualize\n",
    "'''\n",
    "if plot_cities:\n",
    "    for rho in rho_l:\n",
    "        for alpha in alpha_l:\n",
    "            for t_max in t_max_l:\n",
    "                with open(Path(cwd / 'data/{0}_{1}_{2}_{3}.pkl'.format(cty_key, rho, alpha, t_max)), 'rb') as file:\n",
    "                    city = pickle.load(file)\n",
    "                cmap = 'YlOrRd'\n",
    "                figkey = '{0}_{1}_{2}_{3}'.format(cty_key, rho, alpha, t_max)\n",
    "                city.plot(cmap=cmap, figkey=figkey)\n",
    "                '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
