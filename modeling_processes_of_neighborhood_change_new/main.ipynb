{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T00:58:24.317365Z",
     "start_time": "2024-10-21T00:58:20.718614Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "#4-step model:\n",
    "import pandas\n",
    "import geopandas\n",
    "import json\n",
    "import math\n",
    "from haversine import haversine\n",
    "from ipfn import ipfn\n",
    "import networkx\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import patheffects\n",
    "\n",
    "\n",
    "EPSILON = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T01:53:13.054734Z",
     "start_time": "2024-10-21T01:53:13.046237Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, i, dow, city, alpha=0.5):\n",
    "\n",
    "        ''' \n",
    "        Initialize an Agent instance\n",
    "        Parameters:\n",
    "        - i (int): Agent identifier.\n",
    "        - dow (float): Endowment value.\n",
    "        - city (City): Reference to the City instance.\n",
    "        - alpha (float): Weighting factor for transit access vs. community value.\n",
    "        '''\n",
    "        self.i = i\n",
    "        self.dow = dow\n",
    "        self.city = city \n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.weights = np.ones(len(self.city.centroidDict))\n",
    "        self.probabilities = np.ones(len(self.city.centroidDict)) # Probability to go to each centroid\n",
    "        self.tot_probabilities = 0.0\n",
    "        self.avg_probabilities = None\n",
    "        self.u = None\n",
    "\n",
    "        self.reset()\n",
    "        \n",
    "    # Create hash identifier\n",
    "    def __hash__(self):\n",
    "        return hash(self.i)\n",
    "\n",
    "    def __eq__(self, other): \n",
    "        return self.i == other.i\n",
    "\n",
    "    '''\n",
    "    - Assign starting centroid\n",
    "    - Reset centroid weights/probabilities\n",
    "    '''\n",
    "    def reset(self):\n",
    "        # Normalize probabilities\n",
    "        self.probabilities[:] = [a/len(self.probabilities) for a in self.probabilities]\n",
    "        \n",
    "        self.tot_probabilities = np.sum(self.probabilities)\n",
    "        \n",
    "        # Current node - Initialize starting position at random node (based on weights)\n",
    "        self.u = np.random.choice(list(self.city.centroidDict.keys()), p=self.probabilities) \n",
    "        \n",
    "        # Adds self to node\n",
    "        self.city.centroidDict[self.u]['inh'].add(self)\n",
    "\n",
    "# ACTION METHOD\n",
    "    def act(self): \n",
    "        # Leave node\n",
    "        self.city.centroidDict[self.u]['inh'].remove(self) \n",
    "    \n",
    "        # Choose another node\n",
    "        self.u = np.random.choice(list(self.city.centroidDict.keys()), p=self.probabilities) \n",
    "    \n",
    "        # Join node\n",
    "        self.city.centroidDict[self.u]['inh'].add(self) \n",
    "        \n",
    "# LEARN METHOD\n",
    "    def learn(self):\n",
    "        for ID, _ in self.city.centroidDict.items():\n",
    "            self.weights[ID] *= (1 - EPSILON * self.cost(ID)) # Weighted based on COST\n",
    "        \n",
    "        self.probabilities = np.array(self.weights / np.sum(self.weights)) # Normalize\n",
    "        \n",
    "        for a in self.probabilities:\n",
    "            self.tot_probabilities += a # used for averaging purposes\n",
    "\n",
    "# COST FUNCTION\n",
    "    def cost(self, ID):\n",
    "        \n",
    "        # AFFORDABILITY SCORE\n",
    "        # 1 if self.dow >= node.dow_thr; else 0\n",
    "        aff = int(self.dow >= self.city.centroidDict[ID]['dow_thr'])\n",
    "        \n",
    "        # UPKEEP SCORE\n",
    "        # 1 if upkeep == True; else 0\n",
    "        upk = int(self.city.centroidDict[ID]['upk'])\n",
    "        \n",
    "        # BELTLINE SCORE\n",
    "        # 1 if in beltline; else 0\n",
    "        beltline = int(self.city.centroidDict[ID]['beltline'])\n",
    "    \n",
    "        # DISTANCE SCORE\n",
    "        loc = self.city.centroid_distances[self.u, ID] #very simplistic : multiply cost by normalized distance\n",
    "        \n",
    "        # AMENITY ACCESSIBILITY SCORE\n",
    "        acc = np.exp(- (1 - self.alpha) * self.city.amts_dens[ID])\n",
    "        \n",
    "        # COMMUNITY SCORE\n",
    "        # Difference between node 'cmt' value and self.dow.\n",
    "        cmt = np.exp(- self.alpha * np.abs(self.dow - self.city.centroidDict[ID]['cmt']))\n",
    "    \n",
    "        # COST FUNCTION\n",
    "        c = 1 - aff * upk * beltline * loc * cmt * acc\n",
    "        \n",
    "        return c\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# FOUR-STEP MODEL\n",
    "# ===============\n",
    "\n",
    "# SUPPLY data (transportation network):\n",
    "url = 'https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/State_County/MapServer/37/query?where=state%3D06&f=geojson'\n",
    "r = requests.get(url)\n",
    "zones = geopandas.GeoDataFrame.from_features(r.json()['features'])\n",
    "centroidFunction = lambda row: (row['geometry'].centroid.y, row['geometry'].centroid.x)\n",
    "zones['centroid'] = zones.apply(centroidFunction, axis=1)\n",
    "\n",
    "# DEMAND data (transportation network users):\n",
    "url = 'http://api.census.gov/data/2015/acs5/profile?get=NAME,DP03_0018E&for=county&in=state:06'\n",
    "r = requests.get(url)\n",
    "Production = pandas.DataFrame(r.json()[1:], columns = r.json()[0], dtype='int')\n",
    "nameSplit = lambda x: x.split(',')[0]\n",
    "Production['NAME'] = Production['NAME'].apply(nameSplit)\n",
    "zones = pandas.merge(zones, Production)\n",
    "zones['Production'] = zones['DP03_0018E']\n",
    "\n",
    "def getEmployment(state, county):\n",
    "    prefix = 'EN'\n",
    "    seasonal_adjustment = 'U'\n",
    "    area = format(state, \"02d\") + format(county, \"03d\")\n",
    "    data_type = '1'\n",
    "    size = '0'\n",
    "    ownership = '0'\n",
    "    industry = '10'\n",
    "    seriesid = prefix + seasonal_adjustment + area + data_type + size + ownership + industry\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data = json.dumps({\"seriesid\": [seriesid],\"startyear\":\"2015\", \"endyear\":\"2015\", \"registrationKey\": \"\"})\n",
    "    p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "    employment = p.json()['Results']['series'][0]['data'][0]['value']\n",
    "    return(employment)\n",
    "\n",
    "employment = lambda row: int(getEmployment(row['state'], row['county']))\n",
    "zones['Attraction'] = zones.transpose().apply(employment)\n",
    "zones['Production'] = zones['Production'] * zones.sum()['Attraction'] / zones.sum()['Production']\n",
    "zones.index = zones.NAME\n",
    "zones.sort_index(inplace=True)\n",
    "\n",
    "# TRIP DISTRIBUTION:\n",
    "def costFunction(zones, zone1, zone2, beta):\n",
    "    cost = math.exp(-beta * haversine(zones[zone1]['centroid'], zones[zone2]['centroid']))\n",
    "    return(cost)\n",
    "\n",
    "def costMatrixGenerator(zones, costFunction, beta):\n",
    "    originList = []\n",
    "    for originZone in zones:\n",
    "        destinationList = []\n",
    "        for destinationZone in zones:\n",
    "            destinationList.append(costFunction(zones, originZone, destinationZone, beta))\n",
    "        originList.append(destinationList)\n",
    "    return(pandas.DataFrame(originList, index=zones.columns, columns=zones.columns))\n",
    "\n",
    "def tripDistribution(tripGeneration, costMatrix):\n",
    "    costMatrix['ozone'] = costMatrix.columns\n",
    "    costMatrix = costMatrix.melt(id_vars=['ozone'])\n",
    "    costMatrix.columns = ['ozone', 'dzone', 'total']\n",
    "    production = tripGeneration['Production']\n",
    "    production.index.name = 'ozone'\n",
    "    attraction = tripGeneration['Attraction']\n",
    "    attraction.index.name = 'dzone'\n",
    "    aggregates = [production, attraction]\n",
    "    dimensions = [['ozone'], ['dzone']]\n",
    "    IPF = ipfn.ipfn(costMatrix, aggregates, dimensions)\n",
    "    trips = IPF.iteration()\n",
    "    return(trips.pivot(index='ozone', columns='dzone', values='total'))\n",
    "\n",
    "beta = 0.01\n",
    "costMatrix = costMatrixGenerator(zones.transpose(), costFunction, beta)\n",
    "trips = tripDistribution(zones, costMatrix)\n",
    "\n",
    "# MODE CHOICE:\n",
    "def modeChoiceFunction(zones, zone1, zone2, modes):\n",
    "    distance = haversine(zones[zone1]['centroid'], zones[zone2]['centroid'])\n",
    "    probability = {}\n",
    "    total = 0.0\n",
    "    for mode in modes:\n",
    "        total = total + math.exp(modes[mode] * distance)\n",
    "    for mode in modes:\n",
    "        probability[mode] = math.exp(modes[mode] * distance) / total\n",
    "    return(probability)\n",
    "\n",
    "def probabilityMatrixGenerator (zones, modeChoiceFunction, modes):\n",
    "    probabilityMatrix = {}\n",
    "    for mode in modes:\n",
    "        originList = []\n",
    "        for originZone in zones:\n",
    "            destinationList = []\n",
    "            for destinationZone in zones:\n",
    "                destinationList.append(modeChoiceFunction(zones, originZone, destinationZone, modes)[mode])\n",
    "            originList.append(destinationList)\n",
    "        probabilityMatrix[mode] = pandas.DataFrame(originList, index=zones.columns, columns=zones.columns)\n",
    "    return(probabilityMatrix)\n",
    "\n",
    "modes = {'walking': .05, 'cycling': .05, 'driving': .05}\n",
    "probabilityMatrix = probabilityMatrixGenerator(zones.transpose(), modeChoiceFunction, modes)\n",
    "drivingTrips = trips * probabilityMatrix['driving']\n",
    "\n",
    "#ROUTE ASSIGNMENT:\n",
    "def routeAssignment(zones, trips):\n",
    "    G = networkx.Graph()\n",
    "    G.add_nodes_from(zones.columns)\n",
    "    for zone1 in zones:\n",
    "        for zone2 in zones:\n",
    "            if zones[zone1]['geometry'].touches(zones[zone2]['geometry']):\n",
    "                G.add_edge(zone1, zone2, distance = haversine(zones[zone1]['centroid'], zones[zone2]['centroid']), volume=0.0)\n",
    "    for origin in trips:\n",
    "        for destination in trips:\n",
    "            path = networkx.shortest_path(G, origin, destination)\n",
    "            for i in range(len(path) - 1):\n",
    "                G[path[i]][path[i + 1]]['volume'] = G[path[i]][path[i + 1]]['volume'] + trips[zone1][zone2]\n",
    "    return(G)\n",
    "\n",
    "def visualize(G, zones):\n",
    "    fig = pyplot.figure(1, figsize=(10, 10), dpi=90)\n",
    "    ax = fig.add_subplot(111)\n",
    "    zonesT = zones.transpose()\n",
    "    zonesT.plot(ax = ax)\n",
    "    for i, row in zones.transpose().iterrows():\n",
    "        text = pyplot.annotate(s=row['NAME'], xy=((row['centroid'][1], row['centroid'][0])), horizontalalignment='center', fontsize=6)\n",
    "        text.set_path_effects([patheffects.Stroke(linewidth=3, foreground='white'), patheffects.Normal()])\n",
    "    for zone1 in G.edge:\n",
    "        for zone2 in G.edge[zone1]:\n",
    "            volume = G.edge[zone1][zone2]['volume']\n",
    "            x = [zones[zone1]['centroid'][1], zones[zone2]['centroid'][1]]\n",
    "            y = [zones[zone1]['centroid'][0], zones[zone2]['centroid'][0]]\n",
    "            ax.plot(x, y, color='#444444', linewidth=volume/10000, solid_capstyle='round', zorder=1)\n",
    "    pyplot.show(block=False)\n",
    "\n",
    "G = routeAssignment(zones.transpose(), drivingTrips)\n",
    "visualize(G, zones.transpose())\n",
    "\n",
    "# TO PLAY AROUND WITH PARAMETERS (LIST OF PARAMETERS:)\n",
    "# Trip Distribution\n",
    "    #beta = 0.01\n",
    "    #costMatrix = costMatrixGenerator(zones.transpose(), costFunction, beta)\n",
    "    #trips = tripDistribution(zones, costMatrix)\n",
    "# Mode Choice\n",
    "    #modes = {'walking': .05, 'cycling': .05, 'driving': .05}\n",
    "    #probabilityMatrix = probabilityMatrixGenerator(zones.transpose(), modeChoiceFunction, modes)\n",
    "    #drivingTrips = trips * probabilityMatrix['driving']\n",
    "# Route Assignment\n",
    "    #G = routeAssignment(zones.transpose(), drivingTrips)\n",
    "    #visualize(G, zones.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T01:53:12.249571Z",
     "start_time": "2024-10-21T01:53:12.219247Z"
    }
   },
   "outputs": [],
   "source": [
    "class City:\n",
    "\n",
    "    # CONSTRUCTOR\n",
    "    def __init__(self, centroids, g, places, rho=2): #default rho (house capacity) == 2\n",
    "        '''\n",
    "        Initialize a City instance.\n",
    "        '''\n",
    "        self.rho = rho #house capacity\n",
    "        self.centroid = centroids #centroids list\n",
    "        self.g = g #OSMnx map\n",
    "        self.places = places\n",
    "        \n",
    "        # Create a dictionary with each centroid's attributes\n",
    "        self.centroidDict = {} \n",
    "        for ID, (lat, lon, name, beltline) in enumerate(self.centroid): #Iterate through each centroid\n",
    "            self.centroidDict[ID] = {\n",
    "                'lat': lat, # Latitude\n",
    "                'lon': lon, # Longitude\n",
    "                'name': name, # Housing name (region)\n",
    "                'beltline': beltline,  # Is it in the Beltline?\n",
    "                \n",
    "                'inh': set(),  # Set containing all Agent inhabitants\n",
    "                'dow_thr': 0.0,  # Endowment threshold initialized to 0\n",
    "                'upk': False,  # Upkeep score\n",
    "                'cmt': 0.0,  # Community score\n",
    "                'pop_hist': [], # Population history\n",
    "                'cmt_hist': [],  # Community history\n",
    "                \n",
    "                'node': ox.nearest_nodes(self.g, lon, lat)\n",
    "            }\n",
    "        \n",
    "        #compute density of amenities\n",
    "        self.amts_dens = self.compute_amts_dens()\n",
    "        \n",
    "        # Initialize dictionary of distances between centroids\n",
    "        self.centroid_distances = self.compute_centroid_distances()\n",
    "        \n",
    "    # Distances Between Centroids - helper function\n",
    "    def compute_centroid_distances(self):\n",
    "        n = len(self.centroidDict)\n",
    "        distance_matrix = np.zeros((n, n))\n",
    "        \n",
    "        for i in tqdm(range(n), desc=\"Computing centroid distances\"):\n",
    "            source_node = self.centroidDict[i]['node']\n",
    "            lengths = nx.single_source_dijkstra_path_length(self.g, source_node, weight='length')\n",
    "            for j in range(n):\n",
    "                target_node = self.centroidDict[j]['node']\n",
    "                distance = lengths.get(target_node, np.inf)\n",
    "                distance_matrix[i][j] = distance\n",
    "                    \n",
    "        if distance_matrix.max() > 0:\n",
    "            distance_matrix  = distance_matrix/ distance_matrix.max() #normalze\n",
    "\n",
    "        return distance_matrix\n",
    "\n",
    "    # Amenity Density (bus stops) - helper function\n",
    "    def compute_amts_dens(self):\n",
    "        n = len(self.places)\n",
    "        areas = np.zeros(n-1)\n",
    "        bus_stops = np.zeros(n-1)\n",
    "        tags = {'highway':'bus_stop'} #TODO: I don't think this is accurate\n",
    "        \n",
    "        for ID in range(n-1):\n",
    "            place = self.places[ID+1]\n",
    "            print(place)\n",
    "            \n",
    "            # (AREA): Get the boundary polygon of the graph\n",
    "            gdf = ox.geocode_to_gdf(place)\n",
    "            # Project the GDF to a suitable CRS for area calculations\n",
    "            gdf_projected = ox.project_gdf(gdf)\n",
    "            # Calculate the area\n",
    "            area = gdf_projected.area.iloc[0]\n",
    "            areas[ID] = area\n",
    "            \n",
    "            # (AMENITIES): Get polygon\n",
    "            polygon = gdf['geometry'].union_all()\n",
    "            \n",
    "            try:\n",
    "                # Get bus stops within the polygon\n",
    "                gdf_bus = ox.features_from_polygon(polygon, tags)\n",
    "                if gdf_bus.empty:\n",
    "                    bus_stops[ID] = 0\n",
    "                else:\n",
    "                    bus_stops[ID] = len(gdf_bus)\n",
    "            except:\n",
    "                print(f\"No data elements returned for {place}. Setting bus stops to 0.\")\n",
    "                bus_stops[ID] = 0\n",
    "        \n",
    "    \n",
    "        # Calculate density in bus stops per square km\n",
    "        amts_dens = (bus_stops / areas) * 1e6  # Multiply by 1e6 to convert sq meters to sq km\n",
    "        if max(amts_dens) > 0:\n",
    "            amts_dens = amts_dens/max(amts_dens) # Normalize\n",
    "        print (\"Areas:\")\n",
    "        print (areas)\n",
    "        print (\"Number of bus stops:\")\n",
    "        print(bus_stops)\n",
    "        print (\"Normalizd bus stop densities:\")\n",
    "        print (amts_dens)\n",
    "        return amts_dens\n",
    "            \n",
    "\n",
    "    # Set agents and their endowments\n",
    "    def set_agts(self, agts):\n",
    "        self.agts = agts #list of agents\n",
    "        self.agt_dows = np.array([a.dow for a in self.agts]) #array of agent endowments\n",
    "\n",
    "    # Update each node\n",
    "    def update(self):   \n",
    "        for ID, data in self.centroidDict.items(): # For each centroid\n",
    "\n",
    "            pop = len(data['inh']) # Inhabitants\n",
    "            inhabitant_dows = [a.dow for a in data['inh']]  # Array of endowments of node's inhabitants\n",
    "            \n",
    "            # COMMUNITY SCORE (average endowment)\n",
    "            cmt = 0.0\n",
    "            if pop > 0:\n",
    "                distances = self.centroid_distances[ID, [agent.u for agent in data['inh']]]\n",
    "                weights = (1 - distances) ** 2\n",
    "                \n",
    "                if np.sum(weights) > 0:\n",
    "                    cmt = np.average(inhabitant_dows, weights=weights)\n",
    "                data['cmt'] = cmt\n",
    "            \n",
    "            # UPKEEP SCORE\n",
    "            # ENDOWMENT THRESHOLD\n",
    "            if pop > 0: # If inhabited\n",
    "                if pop < self.rho:\n",
    "                    data['dow_thr'] = 0.0\n",
    "                else:\n",
    "                    data['dow_thr'] = np.partition(inhabitant_dows, -self.rho)[-self.rho] # Lowest endowment value if Population = Rho\n",
    "                data['upk'] = True\n",
    "                \n",
    "            else: # If uninhabited\n",
    "                data['dow_thr'] = 0.0\n",
    "                data['upk'] = False\n",
    "\n",
    "            # Update population history\n",
    "            data['pop_hist'].append(pop)\n",
    "            # Update Community history (average endowment)\n",
    "            data['cmt_hist'].append(cmt)\n",
    "        \n",
    "        \n",
    "    # =============\n",
    "    # PLOTTING CODE\n",
    "    # =============\n",
    "    def plot(self, cmap='YlOrRd', figkey='city', graph=None):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "        if graph:\n",
    "            ox.plot_graph(graph, ax=ax, node_color='black', node_size=10, edge_color='gray', edge_linewidth=1, show=False, close=False)\n",
    "    \n",
    "        # Prepare agent data\n",
    "        agent_lats = [self.centroidDict[agent.u]['lat'] for agent in self.agts]\n",
    "        agent_lons = [self.centroidDict[agent.u]['lon'] for agent in self.agts]\n",
    "        agent_wealths = [agent.dow for agent in self.agts]\n",
    "    \n",
    "        # Population density heatmap\n",
    "        heatmap, xedges, yedges = np.histogram2d(agent_lons, agent_lats, bins=30)\n",
    "        extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "        ax.imshow(heatmap.T, extent=extent, origin='lower', cmap=cmap, alpha=0.5)\n",
    "    \n",
    "        # Plot agents with wealth-based marker sizes\n",
    "        norm = Normalize(vmin=min(agent_wealths), vmax=max(agent_wealths))\n",
    "        marker_sizes = [50 + 150 * norm(w) for w in agent_wealths]\n",
    "        sc = ax.scatter(agent_lons, agent_lats, c=agent_wealths, s=marker_sizes, cmap='coolwarm', alpha=0.7, edgecolor='red')\n",
    "    \n",
    "        # Plot centroids locations (this comes after the graph to make sure they are visible on top)\n",
    "        for ID, house in self.centroidDict.items():\n",
    "            lat, lon = house['lat'], house['lon']\n",
    "            color = 'yellow' if house['beltline'] else 'white'\n",
    "            ax.scatter(lon, lat, color=color, s=100, alpha=0.7, edgecolor='black')\n",
    "            \n",
    "            # Display inhabitant populations at each node:\n",
    "            inhabitants = len(house['inh'])\n",
    "            ax.text(lon, lat, str(inhabitants), fontsize=9, ha='center', va='center', color='black')\n",
    "\n",
    "    \n",
    "        # Add color bar for wealth\n",
    "        cbar = plt.colorbar(sc, ax=ax, orientation='vertical', label='Wealth (dow)')\n",
    "    \n",
    "        # Labels and title\n",
    "        ax.set_title(f\"City Visualization: {figkey}\")\n",
    "        ax.set_xlabel(\"Longitude\")\n",
    "        ax.set_ylabel(\"Latitude\")\n",
    "    \n",
    "        # Legend\n",
    "        ax.scatter([], [], c='yellow', s=100, label='Beltline Housing')\n",
    "        ax.scatter([], [], c='white', s=100, label='Non-Beltline Housing')\n",
    "        ax.scatter([], [], c='red', s=100, label='Agents')\n",
    "        ax.legend(loc='upper right')\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./figures/{figkey}.pdf', format='pdf', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T01:53:16.022049Z",
     "start_time": "2024-10-21T01:53:13.526784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tl_2022_us_zcta520.zip already exists in c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\\data. Skipping download.\n",
      "Extracting tl_2022_us_zcta520.zip to c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\\data\\tl_2022_us_zcta520...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 7/7 [00:03<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted tl_2022_us_zcta520.zip to c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\\data\\tl_2022_us_zcta520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def download_and_extract_file(url, filename):\n",
    "    # Use a 'data' subfolder in the current working directory\n",
    "    cwd = Path.cwd()\n",
    "    data_dir = cwd / \"data\"\n",
    "    data_dir.mkdir(exist_ok=True)  # Create the 'data' directory if it doesn't exist\n",
    "    file_path = data_dir / filename\n",
    "\n",
    "    # Create extraction subfolder name (remove .zip extension)\n",
    "    extract_folder_name = filename.rsplit('.', 1)[0]\n",
    "    extract_path = data_dir / extract_folder_name\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if file_path.exists():\n",
    "        print(f\"{filename} already exists in {data_dir}. Skipping download.\")\n",
    "    else:\n",
    "        # Make the request\n",
    "        print(f\"Downloading {filename} to {data_dir}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Get the total file size\n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "            # Open the file and use tqdm for the progress bar\n",
    "            with file_path.open('wb') as file, tqdm(\n",
    "                desc=filename,\n",
    "                total=total_size,\n",
    "                unit='iB',\n",
    "                unit_scale=True,\n",
    "                unit_divisor=1024,\n",
    "            ) as progress_bar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    size = file.write(data)\n",
    "                    progress_bar.update(size)\n",
    "            print(f\"Successfully downloaded {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n",
    "            return\n",
    "\n",
    "    # Extract the ZIP file\n",
    "    print(f\"Extracting {filename} to {extract_path}...\")\n",
    "    extract_path.mkdir(exist_ok=True)  # Create the extraction folder if it doesn't exist\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        # Get the total number of files in the ZIP\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        \n",
    "        # Use tqdm for the extraction progress bar\n",
    "        for file in tqdm(zip_ref.infolist(), desc=\"Extracting\", total=total_files):\n",
    "            zip_ref.extract(file, extract_path)\n",
    "    \n",
    "    print(f\"Successfully extracted {filename} to {extract_path}\")\n",
    "\n",
    "# URL of the file to download\n",
    "url = \"https://www2.census.gov/geo/tiger/TIGER2022/ZCTA520/tl_2022_us_zcta520.zip\"\n",
    "\n",
    "# Filename to save as\n",
    "filename = \"tl_2022_us_zcta520.zip\"\n",
    "\n",
    "# Call the function to download and extract the file\n",
    "download_and_extract_file(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T01:50:53.060468Z",
     "start_time": "2024-10-21T01:50:40.048149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kmmat\\OneDrive\\Desktop\\VIP\\24Fa-MPONC\\modeling_processes_of_neighborhood_change_new\n",
      "College Park, Fulton County, GA, USA\n",
      "East Point, GA\n",
      "Sandy Springs, GA\n",
      "Decatur, DeKalb County, GA\n",
      "Areas:\n",
      "[27975135.28790003 38139324.82998758 99831022.65713052 11498367.60443545]\n",
      "Number of bus stops:\n",
      "[17. 13.  3. 16.]\n",
      "Normalizd bus stop densities:\n",
      "[0.43670979 0.24495514 0.02159593 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing centroid distances: 100%|██████████| 4/4 [00:00<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0\n",
      "t: 1\n",
      "t: 2\n",
      "t: 3\n",
      "t: 4\n",
      "t: 5\n",
      "t: 6\n",
      "t: 7\n",
      "t: 8\n",
      "t: 9\n"
     ]
    }
   ],
   "source": [
    "cwd = Path.cwd()\n",
    "print(cwd)\n",
    "figures_folder = Path(cwd / \"figures\")\n",
    "if not os.path.isdir(figures_folder):\n",
    "    os.makedirs(figures_folder)\n",
    "\n",
    "\n",
    "# Centroids\n",
    "'''centroids = [\n",
    "    (33.7501, 84.3885, 'RDA/Cascade', True),\n",
    "    (33.7501, 84.3885, 'Pittsburgh/Peoplestown', True),\n",
    "    (33.7501, 84.3885, 'Boulevard Crossing', True),\n",
    "    (33.73586185,-84.3709322239104, 'Memorial Drive/Glenwood/Grant Park', True),\n",
    "    (33.7680818,-84.36505111969021, 'Freedom Parkway/Fourth Ward Park', True),\n",
    "    (33.7501, 84.3885, 'Virginia Highlands/Ansley/Piedmont Park', True),\n",
    "    (0.0, 0.0, 'Peachtree/Collier', True),\n",
    "    (0.0, 0.0, 'Upper Westside/Northside', True),\n",
    "    (0.0, 0.0, 'Simpson/Hollowell', True),\n",
    "    (33.779241999999996,-84.43839416079305, 'Upper Marietta/Westside Park', True)'''\n",
    "centroids = [\n",
    "    (33.6534427,-84.4493725, 'College Park', False),\n",
    "    (33.6795531,-84.4393724, 'East Point', False),\n",
    "    (33.9242688,-84.3785379, 'Sandy Springs', True),\n",
    "    (33.7737582,-84.296069, 'Decatur', False),\n",
    "]\n",
    "\n",
    "# (GRAPH APPROACH - automate creation of nodes) \n",
    "# Getting nodes with OSMnx\n",
    "load_g = False\n",
    "if not load_g:\n",
    "    '''gdf = gpd.read_file(cwd / Path('data/tl_2022_us_zcta520/tl_2022_us_zcta520.shp'))\n",
    "    gdf = gdf[gdf['ZCTA5CE20'] == '11206']\n",
    "    shape = gdf.iloc[0].geometry'''\n",
    "    #IF LOADING SPECIFIC SHAPEFILE(S)\n",
    "   \n",
    "    places = [\n",
    "    'Atlanta, GA',\n",
    "    'College Park, Fulton County, GA, USA',\n",
    "    'East Point, GA',\n",
    "    'Sandy Springs, GA',\n",
    "    'Decatur, DeKalb County, GA',\n",
    "    ]\n",
    "    g = ox.graph_from_place(places, network_type='drive', simplify=True)\n",
    "    #Roadmap of Atlanta\n",
    "    g = g.subgraph(max(nx.strongly_connected_components(g), key=len)).copy()\n",
    "    #Ensures all nodes are connected\n",
    "    g = nx.convert_node_labels_to_integers(g)\n",
    "    #Converts nodes to integers\n",
    "   \n",
    "    with open(Path(cwd / 'data/tl_2022_us_zcta520/atlanta.pkl'), 'wb') as file:\n",
    "        pickle.dump(g, file)\n",
    "else:\n",
    "    with open(Path(cwd / 'data/tl_2022_us_zcta520/atlanta.pkl'), 'rb') as file:\n",
    "        g = pickle.load(file)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# SIMULATION PRE-DETERMINED PARAMETERS\n",
    "# ====================================\n",
    "rho_l = [2] #1, 2, 4, 8 (for each iteration) rho-house capacity\n",
    "alpha_l = [0.25] #0.25, 0.75 (for each iteration) lambda - centroid proximity vs. community value\n",
    "t_max_l = [10] #5000, 10000, 15000, 20000 (for each iteration) timesteps\n",
    "tau = 0.5 # inequality factor in Lorentz curve\n",
    "num_agents = 50\n",
    "\n",
    "# RUN SIMULATION?\n",
    "run_experiments = True\n",
    "\n",
    "# PLOT SIMULATION?\n",
    "plot_cities = True\n",
    "\n",
    "cty_key = 'Atlanta'\n",
    "\n",
    "\n",
    "# ===============\n",
    "# SIMULATION CODE\n",
    "# ===============\n",
    "\n",
    "if run_experiments:\n",
    "    for rho in rho_l:\n",
    "        for alpha in alpha_l:\n",
    "\n",
    "            np.random.seed(0)\n",
    "\n",
    "            city = City(centroids, g, places, rho=rho)\n",
    "            agt_dows = np.diff([1 - (1 - x) ** tau for x in np.linspace(0, 1, num_agents + 1)]) \n",
    "            agts = [Agent(i, dow, city, alpha=alpha) for i, dow in enumerate(agt_dows)]\n",
    "\n",
    "            city.set_agts(agts)\n",
    "            city.update()\n",
    "\n",
    "            for t in range(max(t_max_l)):\n",
    "                print('t: {0}'.format(t))\n",
    "                for a in agts:\n",
    "                    a.act()\n",
    "                city.update()\n",
    "                for a in agts:\n",
    "                    a.learn()\n",
    "                \n",
    "                if t + 1 in t_max_l:\n",
    "\n",
    "                    for a in city.agts:\n",
    "                        a.avg_probabilities = a.tot_probabilities / (t + 1)\n",
    "\n",
    "                    with open(Path(cwd / 'data/{0}_{1}_{2}_{3}.pkl'.format(cty_key, rho, alpha, t + 1)), 'wb') as file:\n",
    "                        pickle.dump(city, file)\n",
    "\n",
    "if plot_cities:\n",
    "    for rho in rho_l:\n",
    "        for alpha in alpha_l:\n",
    "            for t_max in t_max_l:\n",
    "                with open(Path(cwd / 'data/{0}_{1}_{2}_{3}.pkl'.format(cty_key, rho, alpha, t_max)), 'rb') as file:\n",
    "                    city = pickle.load(file)\n",
    "                cmap = 'YlOrRd'\n",
    "                figkey = '{0}_{1}_{2}_{3}'.format(cty_key, rho, alpha, t_max)\n",
    "                city.plot(cmap=cmap, figkey=figkey, graph=g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
