{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:22:28.111198Z",
     "start_time": "2024-10-07T02:22:28.104546Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "\n",
    "EPSILON = 1e-3"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:41:12.299570Z",
     "start_time": "2024-10-07T02:41:12.279140Z"
    }
   },
   "source": [
    "class City:\n",
    "\n",
    "    # CONSTRUCTOR\n",
    "    def __init__(self, housing, amts, rho=2): #default rho (house capacity) == 2\n",
    "\n",
    "        self.rho = rho #house capacity\n",
    "        self.amts = amts #amenity list\n",
    "        self.housing = housing #housing list\n",
    "        \n",
    "        # Create dictionary containing ID and tuple from 'housing' list\n",
    "        self.housingDict = {} \n",
    "        for ID, (lat, lon, name, beltline) in enumerate(self.housing): #Iterate through each housing node\n",
    "            self.housingDict[ID] = {\n",
    "                'lat': lat, # Latitude\n",
    "                'lon': lon, # Longitude\n",
    "                'name': name, # Housing name (region)\n",
    "                'beltline': beltline,  # Is it in the Beltline?\n",
    "                \n",
    "                'amt': False,  # Is it an amenity?\n",
    "                'inh': set(),  # Set containing all Agent inhabitants\n",
    "                'dow_thr': 0.0,  # Endowment threshold initialized to 0\n",
    "                'upk': False,  # Upkeep score\n",
    "                'cmt': 0.0,  # Community score\n",
    "                'pop_hist': [], # Population history\n",
    "                'cmt_hist': []  # Community history\n",
    "            }\n",
    "            \n",
    "        #Create dictionary containing ID and tuple from 'amts' list\n",
    "        self.amtsDict = {}\n",
    "        for ID, (lat, lon, name, beltline) in enumerate(self.amts): #Iterate through each housing node\n",
    "            self.amtsDict[ID+len(self.housing)] = {\n",
    "                'lat': lat, # Latitude\n",
    "                'lon': lon, # Longitude\n",
    "                'name': name, # Name\n",
    "                'beltline': beltline,  # Is it in the Beltline?\n",
    "                \n",
    "                'amt': True,  # Is it an amenity?\n",
    "\n",
    "                'inh': None,  # Set containing all Agent inhabitants\n",
    "                'dow_thr': None, # Endowment threshold initialized to 0\n",
    "                'upk': None,  # Upkeep score\n",
    "                'cmt': 0.0,  # Community score\n",
    "                'pop_hist': None,  # Population history\n",
    "                'cmt_hist': None  # Community history\n",
    "            }\n",
    "\n",
    "        # Set transit amenities [GRAPH APPROACH]\n",
    "        '''def set_amts(self, amts):\n",
    "        self.amts = amts\n",
    "        for u in self.amts:\n",
    "            data = self.housingDict[u]\n",
    "            \n",
    "            # Node characteristics of an amenity node\n",
    "            data['amt'] = True\n",
    "            data['beltline'] = self.amts[u][3]\n",
    "            data['inh'] = None\n",
    "            data['dow_thr'] = None\n",
    "            data['upk'] = None\n",
    "            data['cmt'] = None\n",
    "            data['pop_hist'] = None\n",
    "            data['cmt_hist'] = None\n",
    "            \n",
    "        # Calculate shortest distance between each housing node & transit node \n",
    "        # NECESSARY FOR ACCESSIBILITY SCORE\n",
    "        if len(self.amts) == 0:\n",
    "            self.amts_dist = None\n",
    "        else:\n",
    "            self.amts_dist = np.array([self.calcDistance(node1, node2) for node1 in self.housing for node2 in self.amts])'''\n",
    "        \n",
    "        # Dictionary containing all nodes\n",
    "        self.allNodes = {**self.housingDict, **self.amtsDict}\n",
    "\n",
    "        # Fill self.housing_dist [GRAPH APPROACH] \n",
    "        ''' \n",
    "        self.diam = nx.diameter(self.g, weight='length') #Longest shortest path between any two nodes on graph\n",
    "        \n",
    "        #Normalized shortest paths between all pairs of nodes\n",
    "        self.housing_dist = dict(nx.all_pairs_dijkstra_path_length(self.g, weight='length'))\n",
    "        self.housing_dist = pd.DataFrame.from_dict(self.housing_dist).sort_index() / self.diam #\n",
    "        self.housing_dist = self.housing_dist.to_numpy()'''\n",
    "\n",
    "        self.housing_dist = {} # Dictionary of distances btw housing node pairs   \n",
    "        self.get_housing_distances() # Fill self.housing_dist dictionary\n",
    "\n",
    "        self.amts_dist = {} # Dictionary of distances btw housing and amenity \n",
    "        self.get_amt_distances() # Fill self.housing_dist dictionary\n",
    "\n",
    "        self.agts = None #List of agents\n",
    "        self.agt_dows = None #List of agent endowments\n",
    "\n",
    "\n",
    "    # HELPER FUNCTION - fill self.housing_dist dictionary\n",
    "    def get_housing_distances(self):\n",
    "        numHousing = len(self.housingDict)\n",
    "        self.housing_dist = np.zeros((numHousing, numHousing))\n",
    "        \n",
    "        for ID1, node1 in self.housingDict.items():\n",
    "            for ID2, node2 in self.housingDict.items():\n",
    "                if ID1 <= ID2:  \n",
    "                    # Indices [ID1][ID2] & [ID2][ID1] have the same distance\n",
    "                    distance = self.calcDistance(node1, node2)\n",
    "                    self.housing_dist[ID1][ID2] = distance\n",
    "                    self.housing_dist[ID2][ID1] = distance\n",
    "\n",
    "        #normalize with longest shortest distance\n",
    "        if self.housing_dist.size != 0:\n",
    "            self.housing_dist = self.housing_dist / np.max(self.housing_dist) \n",
    "    \n",
    "    # HELPER FUNCTION - fill self.amts_dist dictionary\n",
    "    def get_amt_distances(self):\n",
    "        numHousing = len(self.housingDict)\n",
    "        numAmts = len(self.amtsDict)\n",
    "        self.amts_dist = np.zeros((numHousing, numAmts))\n",
    "        \n",
    "        for ID1, node1 in self.housingDict.items():\n",
    "            for ID2, node2 in self.amtsDict.items():\n",
    "                distance = self.calcDistance(node1, node2)\n",
    "                self.amts_dist[ID1][ID2 - len(self.housing)] = distance\n",
    "\n",
    "        #normalize with longest shortest distance\n",
    "        if self.amts_dist.size != 0:\n",
    "            self.amts_dist = self.amts_dist / np.max(self.amts_dist) \n",
    "\n",
    "    # HELPER FUNCTION - calculates distance between ANY two nodes\n",
    "    def calcDistance(self, node1, node2):\n",
    "        # PROCESS FOR CALCULATING (HAVERSINE) GEOGRAPHIC DISTANCES\n",
    "        R = 6371.0 # Earth radius (km)\n",
    "        lat1 = np.radians(node1['lat'])\n",
    "        lon1 = np.radians(node1['lon'])\n",
    "        lat2 = np.radians(node2['lat'])\n",
    "        lon2 = np.radians(node2['lon'])\n",
    "\n",
    "        # Haversine formula\n",
    "        a = np.sin((lat2 - lat1) / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin((lon2 - lon1) / 2)**2\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "        distance = R * c\n",
    "        return distance\n",
    "\n",
    "    def set_agts(self, agts):\n",
    "        self.agts = agts #list of agents\n",
    "        self.agt_dows = np.array([a.dow for a in self.agts]) #array of agent endowments\n",
    "\n",
    "    # Update each node\n",
    "    def update(self):\n",
    "        for ID, data in self.housingDict.items(): # Iterate through dict\n",
    "            # Skip amenity nodes\n",
    "            if data['amt']:\n",
    "                continue\n",
    "\n",
    "            pop = len(data['inh']) # Population\n",
    "            \n",
    "            # COMMUNITY SCORE (average endowment)\n",
    "            if pop > 0:\n",
    "                #average endowment of agents in set data['inh'], weighted by alpha\n",
    "                cmt = np.average(self.agt_dows, weights=[(1 - self.housing_dist[ID][a.u]) ** 2 for a in data['inh']]) \n",
    "\n",
    "                data['cmt'] = cmt\n",
    "            else:\n",
    "                data['cmt'] = 0.0\n",
    "            \n",
    "            # UPKEEP SCORE\n",
    "            # ENDOWMENT THRESHOLD\n",
    "            if pop > 0: # If inhabited\n",
    "                if pop < self.rho:\n",
    "                    data['dow_thr'] = 0.0\n",
    "                else:\n",
    "                    data['dow_thr'] = sorted([a.dow for a in data['inh']])[-self.rho] # Lowest endowment value if Population = Rho\n",
    "                data['upk'] = True\n",
    "                \n",
    "            else: # If uninhabited\n",
    "                data['dow_thr'] = 0.0\n",
    "                data['upk'] = False\n",
    "\n",
    "            # Update population history\n",
    "            data['pop_hist'].append(pop)\n",
    "            \n",
    "            # Update Community history (average endowment)\n",
    "            data['cmt_hist'].append(cmt)\n",
    "        \n",
    "\n",
    "#[GRAPH APPROACH]\n",
    "# 'plot' function\n",
    "'''\n",
    "    def plot(self, cmap='YlOrRd', figkey=None):\n",
    "\n",
    "        for u, data in self.g.nodes(data=True):\n",
    "            if not data['amt']: # Non-transit nodes\n",
    "                data['dow'] = np.average(self.agt_dows, weights=[a.avg_probabilities[u] for a in self.agts]) # Average endowment\n",
    "                data['dow'] = (data['dow'] - min(city.agt_dows)) / (max(city.agt_dows) - min(city.agt_dows)) # Normalize\n",
    "                \n",
    "                data['pop'] = np.sum([a.avg_probabilities[u] for a in self.agts]) # Sum agent probabilities to be at the node\n",
    "            else: # Transit nodes\n",
    "                data['dow'] = np.nan\n",
    "                data['pop'] = np.nan\n",
    "\n",
    "        # ===============================\n",
    "        # SIMULATION VISUALIZATION - CODE\n",
    "        # ===============================\n",
    "        no_agts = len(self.agts) # Number of agents\n",
    "        \n",
    "        \n",
    "        # Size of nodes\n",
    "        node_size = [no_agts / 10 * data['pop'] if not data['amt'] else no_agts / 2.5 for _, data in self.g.nodes(data=True)]\n",
    "        \n",
    "        # Color of nodes\n",
    "        node_color = ox.plot.get_node_colors_by_attr(self.g, 'dow', start=0, stop=1, na_color='b', cmap=cmap)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "        # COLORBAR\n",
    "        cb = fig.colorbar(\n",
    "            plt.cm.ScalarMappable(cmap=plt.colormaps[cmap]), ax=ax, location='bottom', shrink=0.5, pad=0.05\n",
    "        )\n",
    "        cb.set_label('Expected Endowment', fontsize=14)\n",
    "        \n",
    "        # PLOT GRAPH\n",
    "        ox.plot_graph(self.g, ax=ax, bgcolor='w', node_color=node_color, node_size=node_size)\n",
    "        plt.show()\n",
    "        \n",
    "        if figkey is not None:\n",
    "            plt.savefig('./figures/{0}.pdf'.format(figkey), bbox_inches='tight', format='pdf')\n",
    "        # Save graph as pdf in './figures/' directory if 'figkey' is provided\n",
    "        '''"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    def plot(self, cmap='YlOrRd', figkey=None):\\n\\n        for u, data in self.g.nodes(data=True):\\n            if not data['amt']: # Non-transit nodes\\n                data['dow'] = np.average(self.agt_dows, weights=[a.avg_probabilities[u] for a in self.agts]) # Average endowment\\n                data['dow'] = (data['dow'] - min(city.agt_dows)) / (max(city.agt_dows) - min(city.agt_dows)) # Normalize\\n                \\n                data['pop'] = np.sum([a.avg_probabilities[u] for a in self.agts]) # Sum agent probabilities to be at the node\\n            else: # Transit nodes\\n                data['dow'] = np.nan\\n                data['pop'] = np.nan\\n\\n        # ===============================\\n        # SIMULATION VISUALIZATION - CODE\\n        # ===============================\\n        no_agts = len(self.agts) # Number of agents\\n        \\n        \\n        # Size of nodes\\n        node_size = [no_agts / 10 * data['pop'] if not data['amt'] else no_agts / 2.5 for _, data in self.g.nodes(data=True)]\\n        \\n        # Color of nodes\\n        node_color = ox.plot.get_node_colors_by_attr(self.g, 'dow', start=0, stop=1, na_color='b', cmap=cmap)\\n        \\n        fig, ax = plt.subplots(figsize=(9, 6))\\n\\n        # COLORBAR\\n        cb = fig.colorbar(\\n            plt.cm.ScalarMappable(cmap=plt.colormaps[cmap]), ax=ax, location='bottom', shrink=0.5, pad=0.05\\n        )\\n        cb.set_label('Expected Endowment', fontsize=14)\\n        \\n        # PLOT GRAPH\\n        ox.plot_graph(self.g, ax=ax, bgcolor='w', node_color=node_color, node_size=node_size)\\n        plt.show()\\n        \\n        if figkey is not None:\\n            plt.savefig('./figures/{0}.pdf'.format(figkey), bbox_inches='tight', format='pdf')\\n        # Save graph as pdf in './figures/' directory if 'figkey' is provided\\n        \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:30:25.078038Z",
     "start_time": "2024-10-07T02:30:25.071756Z"
    }
   },
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, i, dow, city, alpha=0.5):\n",
    "\n",
    "        self.i = i # Agent instance identifier\n",
    "        self.dow = dow #endowment\n",
    "        self.city = city #city\n",
    "        self.alpha = alpha #Transit_access/Community weight\n",
    "\n",
    "        self.weights = None\n",
    "        self.probabilities = None\n",
    "        self.tot_probabilities = None\n",
    "        self.avg_probabilities = None\n",
    "        self.u = None\n",
    "\n",
    "        self.reset()\n",
    "        \n",
    "    # Create hash identifier\n",
    "    def __hash__(self):\n",
    "        return hash(self.i)\n",
    "\n",
    "    def __eq__(self, other): \n",
    "        return self.i == other.i\n",
    "\n",
    "# RESET METHOD\n",
    "    def reset(self):\n",
    "        # Assign weight 1 to housing nodes, weight 0 for transit nodes\n",
    "        self.weights = np.array([1.0 if not data['amt'] else 0 for data in self.city.allNodes.values()]) \n",
    "        \n",
    "        # Normalize probabilities\n",
    "        self.probabilities = np.array(self.weights / self.weights.sum())\n",
    "        \n",
    "        self.tot_probabilities = self.probabilities.copy()\n",
    "        \n",
    "        # Current node - Initialize starting position at random node (based on weights)\n",
    "        self.u = np.random.choice(list(self.city.housingDict.keys()), p=self.probabilities) \n",
    "        \n",
    "        # Adds self to node\n",
    "        self.city.housingDict[self.u]['inh'].add(self)\n",
    "\n",
    "# ACTION METHOD\n",
    "    def act(self): \n",
    "        # Leave node\n",
    "        self.city.housingDict[self.u]['inh'].remove(self) \n",
    "    \n",
    "        # Choose another node\n",
    "        self.u = np.random.choice(list(self.city.housingDict.keys()), p=self.probabilities) \n",
    "    \n",
    "        # Join node\n",
    "        self.city.housingDict[self.u]['inh'].add(self) \n",
    "        \n",
    "# LEARN METHOD\n",
    "    def learn(self):\n",
    "        for ID, data in self.city.housingDict.items(): # for each node\n",
    "            if not data['amt']: # if not transit 'amt'\n",
    "                self.weights[ID] *= (1 - EPSILON * self.cost(ID)) # adjust probability weights based off Cost Function\n",
    "        \n",
    "        self.probabilities = np.array(self.weights / self.weights.sum()) # normalize weights\n",
    "        self.tot_probabilities += self.probabilities # used for averaging purposes\n",
    "\n",
    "# COST FUNCTION\n",
    "    def cost(self, ID):\n",
    "        \n",
    "        # AFFORDABILITY SCORE\n",
    "        # 1 if self.dow >= node.dow_thr; else 0\n",
    "        aff = int(self.dow >= self.city.housingDict[ID]['dow_thr'])\n",
    "        \n",
    "        # UPKEEP SCORE\n",
    "        # 1 if upkeep == True; else 0\n",
    "        upk = int(self.city.housingDict[ID]['upk'])\n",
    "        \n",
    "        # BELTLINE SCORE\n",
    "        # 1 if in beltline; else 0\n",
    "        beltline = int(self.city.housingDict[ID]['beltline'])\n",
    "    \n",
    "        # DISTANCE SCORE\n",
    "         # 1 if no amenities, \n",
    "        if  not self.amtsDict:\n",
    "            loc = 1 \n",
    "        else:\n",
    "            loc = np.exp(- (1 - self.alpha) * self.city.amts_dist[ID])\n",
    "        \n",
    "        # COMMUNITY SCORE\n",
    "        # Difference between node 'cmt' value and self.dow.\n",
    "        cmt = np.exp(- self.alpha * np.abs(self.dow - self.city.housingDict[ID]['cmt']))\n",
    "    \n",
    "        # COST FUNCTION\n",
    "        c = 1 - aff * loc * beltline * upk * cmt\n",
    "        \n",
    "        return c"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:25:00.915559Z",
     "start_time": "2024-10-07T02:24:58.633375Z"
    }
   },
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_and_extract_file(url, filename):\n",
    "    # Use a 'data' subfolder in the current working directory\n",
    "    cwd = Path.cwd()\n",
    "    data_dir = cwd / \"data\"\n",
    "    data_dir.mkdir(exist_ok=True)  # Create the 'data' directory if it doesn't exist\n",
    "    file_path = data_dir / filename\n",
    "\n",
    "    # Create extraction subfolder name (remove .zip extension)\n",
    "    extract_folder_name = filename.rsplit('.', 1)[0]\n",
    "    extract_path = data_dir / extract_folder_name\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if file_path.exists():\n",
    "        print(f\"{filename} already exists in {data_dir}. Skipping download.\")\n",
    "    else:\n",
    "        # Make the request\n",
    "        print(f\"Downloading {filename} to {data_dir}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Get the total file size\n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "            # Open the file and use tqdm for the progress bar\n",
    "            with file_path.open('wb') as file, tqdm(\n",
    "                desc=filename,\n",
    "                total=total_size,\n",
    "                unit='iB',\n",
    "                unit_scale=True,\n",
    "                unit_divisor=1024,\n",
    "            ) as progress_bar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    size = file.write(data)\n",
    "                    progress_bar.update(size)\n",
    "            print(f\"Successfully downloaded {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}. Status code: {response.status_code}\")\n",
    "            return\n",
    "\n",
    "    # Extract the ZIP file\n",
    "    print(f\"Extracting {filename} to {extract_path}...\")\n",
    "    extract_path.mkdir(exist_ok=True)  # Create the extraction folder if it doesn't exist\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        # Get the total number of files in the ZIP\n",
    "        total_files = len(zip_ref.infolist())\n",
    "        \n",
    "        # Use tqdm for the extraction progress bar\n",
    "        for file in tqdm(zip_ref.infolist(), desc=\"Extracting\", total=total_files):\n",
    "            zip_ref.extract(file, extract_path)\n",
    "    \n",
    "    print(f\"Successfully extracted {filename} to {extract_path}\")\n",
    "\n",
    "# URL of the file to download\n",
    "url = \"https://www2.census.gov/geo/tiger/TIGER2022/ZCTA520/tl_2022_us_zcta520.zip\"\n",
    "\n",
    "# Filename to save as\n",
    "filename = \"tl_2022_us_zcta520.zip\"\n",
    "\n",
    "# Call the function to download and extract the file\n",
    "download_and_extract_file(url, filename)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tl_2022_us_zcta520.zip already exists in /Users/devammondal/PycharmProjects/24Fa-MPONC/modeling_processes_of_neighborhood_change_new/data. Skipping download.\n",
      "Extracting tl_2022_us_zcta520.zip to /Users/devammondal/PycharmProjects/24Fa-MPONC/modeling_processes_of_neighborhood_change_new/data/tl_2022_us_zcta520...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 7/7 [00:02<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted tl_2022_us_zcta520.zip to /Users/devammondal/PycharmProjects/24Fa-MPONC/modeling_processes_of_neighborhood_change_new/data/tl_2022_us_zcta520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T02:41:15.634203Z",
     "start_time": "2024-10-07T02:41:15.588402Z"
    }
   },
   "source": [
    "cwd = Path.cwd()\n",
    "print(cwd)\n",
    "figures_folder = Path(cwd / \"figures\")\n",
    "if not os.path.isdir(figures_folder):\n",
    "    os.makedirs(figures_folder)\n",
    "\n",
    "\n",
    "# Housing amenities [manual]\n",
    "# Use dummy coordinates for now\n",
    "housing = [\n",
    "    (0.0, 0.0, 'RDA/Cascade', True),\n",
    "    (0.0, 0.0, 'Pittsburgh/Peoplestown', True),\n",
    "    (0.0, 0.0, 'Boulevard Crossing', True),\n",
    "    (0.0, 0.0, 'Memorial Drive/Glenwood', True),\n",
    "    (0.0, 0.0, 'Freedom Parkway', True),\n",
    "    (0.0, 0.0, 'Virginia Highlands/Ansley', True),\n",
    "    (0.0, 0.0, 'Peachtree/Collier', True),\n",
    "    (0.0, 0.0, 'Upper Westside/Northside', True),\n",
    "    (0.0, 0.0, 'Simpson/Hollowell', True),\n",
    "    (0.0, 0.0, 'Upper Marietta/Westside Park', True),\n",
    "\n",
    "    (0.0, 0.0, 'Westlake HS', False), #4280\n",
    "    (0.0, 0.0, 'Wheeler HS', False), #4292\n",
    "    (0.0, 0.0, 'Lakeside HS', False), #4294\n",
    "    (0.0, 0.0, 'Druid Hills HS', False), #4307\n",
    "    (0.0, 0.0, 'McNair, Ronald E. HS', False), #4315\n",
    "    (0.0, 0.0, 'Brookhaven City', False), #4387\n",
    "    (0.0, 0.0, 'Decatur City', False), #4444\n",
    "    (0.0, 0.0, 'East Point City', False), #4459\n",
    "    (0.0, 0.0, 'Hapeville City', False), #4504\n",
    "    (0.0, 0.0, 'Sandy Springs City', False), #4646\n",
    "\n",
    "]\n",
    "\n",
    "# (GRAPH APPROACH - automate creation of nodes)\n",
    "'''\n",
    "load_g = False\n",
    "if not load_g:\n",
    "    gdf = gpd.read_file(cwd / Path('data/tl_2022_us_zcta520/tl_2022_us_zcta520.shp'))\n",
    "    gdf = gdf[gdf['ZCTA5CE20'] == '11206']\n",
    "    shape = gdf.iloc[0].geometry\n",
    "    g = ox.graph_from_polygon(shape, network_type='drive', simplify=True)\n",
    "    g = g.subgraph(max(nx.strongly_connected_components(g), key=len)).copy()\n",
    "    g = nx.convert_node_labels_to_integers(g)\n",
    "    with open(Path(cwd / 'data/tl_2022_us_zcta520/williamsburg.pkl'), 'wb') as file:\n",
    "        pickle.dump(g, file)\n",
    "else:\n",
    "    with open(Path(cwd / 'data/tl_2022_us_zcta520/williamsburg.pkl'), 'rb') as file:\n",
    "        g = pickle.load(file)\n",
    "amts = [ox.nearest_nodes(g, lon, lat) for lat, lon, _ in stations]\n",
    "'''\n",
    "\n",
    "# For now, don't consider transit amenities:\n",
    "# Tuple format: (lat) float, (lon) float, (name) string, (in beltline?) boolean\n",
    "amts = []\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# SIMULATION PRE-DETERMINED PARAMETERS\n",
    "# ====================================\n",
    "rho_l = [1, 2, 4, 8] # (for each iteration) rho-house capacity\n",
    "alpha_l = [0.25, 0.75] # (for each iteration) lambda-transit access vs. community value\n",
    "t_max_l = [5000, 10000, 15000, 20000] # (for each iteration) timesteps\n",
    "tau = 0.5 # inequality factor in Lorentz curve\n",
    "\n",
    "# RUN SIMULATION?\n",
    "run_experiments = True\n",
    "\n",
    "# PLOT SIMULATION?\n",
    "plot_cities = True\n",
    "\n",
    "cty_key = 'williamsburg'\n",
    "\n",
    "\n",
    "# ===============\n",
    "# SIMULATION CODE\n",
    "# ===============\n",
    "\n",
    "if run_experiments:\n",
    "    for rho in rho_l:\n",
    "        for alpha in alpha_l:\n",
    "\n",
    "            np.random.seed(0)\n",
    "\n",
    "            city = City(housing, amts, rho=rho)\n",
    "            #city.set_amts(amts) [graph approach to setting amenities]\n",
    "            n = len(city.allNodes)\n",
    "            \n",
    "            agt_dows = np.diff([1 - (1 - x) ** tau for x in np.linspace(0, 1, n + 1)])\n",
    "            agts = [Agent(i, dow, city, alpha=alpha) for i, dow in enumerate(agt_dows)]\n",
    "\n",
    "            city.set_agts(agts)\n",
    "            city.update()\n",
    "\n",
    "            for t in range(max(t_max_l)):\n",
    "                print('t: {0}'.format(t))\n",
    "                for a in agts:\n",
    "                    a.act()\n",
    "                city.update()\n",
    "                for a in agts:\n",
    "                    a.learn()\n",
    "\n",
    "                if t + 1 in t_max_l:\n",
    "\n",
    "                    for a in city.agts:\n",
    "                        a.avg_probabilities = a.tot_probabilities / (t + 1)\n",
    "\n",
    "                    with open(Path(cwd / 'data/{0}_{1}_{2}_{3}.pkl'.format(cty_key, rho, alpha, t + 1)), 'wb') as file:\n",
    "                        pickle.dump(city, file)\n",
    "\n",
    "#[GRAPH APPROACH]\n",
    "#TODO: figure out how to visualize\n",
    "'''\n",
    "if plot_cities:\n",
    "    for rho in rho_l:\n",
    "        for alpha in alpha_l:\n",
    "            for t_max in t_max_l:\n",
    "                with open(Path(cwd / 'data/{0}_{1}_{2}_{3}.pkl'.format(cty_key, rho, alpha, t_max)), 'rb') as file:\n",
    "                    city = pickle.load(file)\n",
    "                cmap = 'YlOrRd'\n",
    "                figkey = '{0}_{1}_{2}_{3}'.format(cty_key, rho, alpha, t_max)\n",
    "                city.plot(cmap=cmap, figkey=figkey)\n",
    "                '''"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/devammondal/PycharmProjects/24Fa-MPONC/modeling_processes_of_neighborhood_change_new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/yv_2sbb929330plxnsscsby80000gn/T/ipykernel_98739/3008067175.py:107: RuntimeWarning: invalid value encountered in divide\n",
      "  self.housing_dist = self.housing_dist / np.max(self.housing_dist)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Axis must be specified when shapes of a and weights differ.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 93\u001B[0m\n\u001B[1;32m     90\u001B[0m agts \u001B[38;5;241m=\u001B[39m [Agent(i, dow, city, alpha\u001B[38;5;241m=\u001B[39malpha) \u001B[38;5;28;01mfor\u001B[39;00m i, dow \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(agt_dows)]\n\u001B[1;32m     92\u001B[0m city\u001B[38;5;241m.\u001B[39mset_agts(agts)\n\u001B[0;32m---> 93\u001B[0m \u001B[43mcity\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mmax\u001B[39m(t_max_l)):\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(t))\n",
      "Cell \u001B[0;32mIn[28], line 156\u001B[0m, in \u001B[0;36mCity.update\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;66;03m# COMMUNITY SCORE (average endowment)\u001B[39;00m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pop \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;66;03m#average endowment of agents in set data['inh'], weighted by alpha\u001B[39;00m\n\u001B[0;32m--> 156\u001B[0m     cmt \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magt_dows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhousing_dist\u001B[49m\u001B[43m[\u001B[49m\u001B[43mID\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mu\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \n\u001B[1;32m    158\u001B[0m     data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcmt\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m cmt\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/AtlantaBeltlineAnalysis/.venv/lib/python3.12/site-packages/numpy/lib/function_base.py:534\u001B[0m, in \u001B[0;36maverage\u001B[0;34m(a, axis, weights, returned, keepdims)\u001B[0m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m a\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m wgt\u001B[38;5;241m.\u001B[39mshape:\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 534\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    535\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAxis must be specified when shapes of a and weights \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    536\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiffer.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    537\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m wgt\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    538\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    539\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1D weights expected when shapes of a and weights differ.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Axis must be specified when shapes of a and weights differ."
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
